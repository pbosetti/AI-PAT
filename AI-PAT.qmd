---
title: "Come funziona l’Intelligenza Artificiale"
subtitle: |
  Tr.A.In. ---
  Nuovi modi di lavorare nella PA: intelligenza artificiale, spazi e tempi
author: "Paolo Bosetti"
institute: "Dipartimento di Ingegneria Industriale\n\nUniversità di Trento"
date: 2025-11-22
modified-date: today
format: 
  revealjs: default
email-obfuscation: javascript
transition: none
transition-speed: fast
---

```{r setup}
knitr::opts_chunk$set(
	echo = FALSE,
	message = FALSE,
	warning = FALSE
)
library(tidyverse)
library(modelr)
library(patchwork)
library(MASS)
```


# Contenuti

* Contesto: **Machine Learning**
* Un esempio semplice
* Il **Deep Learning**
  - principi
  - sviluppo
  - allucinazioni
* AI per le masse
* Rischi dell'AI


# AI e *Machine Learning*
:::{style="text-align: center;"}
![](https://www.researchgate.net/publication/354124420/figure/fig3/AS:11431281386363922@1745064368955/Relationship-between-artificial-intelligence-machine-learning-neural-network-and-deep.tif){width="50%"}
:::

# AI e *Machine Learning*
:::{style="text-align: center;"}
![](images/classification.png){width="80%"}
:::

## Cos'è il *machine learning*

:::columns
:::{.column width=60%}
* Ciò che oggi è di dominio comune è solo una delle numerose tecniche che vanno sotto il nome di ***machine learning***
* *Machine learning* significa realizzare ed usare una procedura di calcolo che fornisce predizioni sulla base di **un'esperienza**
* La *procedura di calcolo* si chiama **modello**
* *calibrare i parametri* del modello si chiama **addestramento**
* *utilizzare* la procedura si chiama **inferenza**
:::

:::{.column width=40%}
```{dot p_diagram}
digraph p_diagram {
  rankdir="TB"
  node [shape="box" color="white" fontname="Helvetica"]
  A [label = "Predittori"]
  P [label="MODELLO" fontcolor="white" fillcolor="black" style="filled"]
  Y [label="Predizione"]

  A -> P
  P -> Y
}
```
:::
:::

:::callout-note
Un modello può essere visto come una **black-box** che effettua una trasformazione tra ingressi (predittori) e uscita (predizione)
:::

## Però

:::columns
:::{.column width=60%}
* Il modello fornisce una predizione su base **probabilistica**
* L'affidabilità del modello degrada quando **estrapola** cioè quando fornisce predizioni a partire da condizioni per le quali non è stato addestrato
* Comprendere potenzialità e limiti di un modello predittivo **richiede comprensione degli aspetti statistici** legati alla sua creazione e addestramento
:::

:::{.column width=40%}
```{dot ref.label="p_diagram"}
```
:::
:::

:::callout-warning
Più è complesso il modello, più la comprensione è difficile e **maggiore è la responsabilità** assunta dall'utente (o, se si preferisce, la cieca fiducia riposta nel sistema ML...)
:::


# *Deep learning* e le reti neurali profonde


## Cos'è una rete neurale

:::columns
:::column
Le **reti neurali artificiali** sono un concetto non nuovo:

* una regressione lineare è la rete neurale più semplice, inventata da Gauss nel **1795**
* Rosenblatt (**1958**) ha dato la prima formulazione di una rete basata su collegamenti tra neuroni (*perceptron*)
* Reti LSTM proposte dal Hochreiter nel **1995**
* Andrew Ng, addestramento di DNN su GPU, **2009**
:::

:::{.column style="text-align: center;"}
```{dot nnet}
digraph nn {
  rankdir="LR";
  splines=false;
  node [fontname="Helvetica", fontsize=12];
  edge [fontname="Helvetica", fontsize=8, fontcolor="#000099"];
  subgraph input {
    label=input;
    altezza
    peso
  }
  subgraph hidden {
    label=hidden;
    n1;
    n2;
    n3;
  }
  subgraph output {
    label=output
    maschio;
    femmina;
  }
  
  altezza -> n1 [xlabel="w1"]
  altezza -> n2 [xlabel = "w2"]
  altezza -> n3 [xlabel = "w3"]
  peso -> n1 [xlabel = "w4"]
  peso -> n2 [xlabel = "w5"]
  peso -> n3 [xlabel = "w6"]
  n1 -> maschio [xlabel = "w7"]
  n2 -> maschio [xlabel = "w8"]
  n3 -> maschio [xlabel = "w9"]
  n1 -> femmina [xlabel = "w10"]
  n2 -> femmina [xlabel = "w11"]
  n3 -> femmina [xlabel = "w12"]
}
```

:::
:::

## Esempio: addestramento

```{r}
set.seed(0)
male <- mvrnorm(n=1000, mu=c(170,75), Sigma=matrix(c(20, 12, 12, 20), nrow=2)) %>% 
  as_tibble() %>% 
  rename(height = V1, mass = V2) %>% 
  mutate(gender="maschio")

female <- mvrnorm(n=1000, mu=c(160,60), Sigma=matrix(c(20, 10, 15, 20), nrow=2)) %>% 
  as_tibble() %>% 
  rename(height = V1, mass = V2) %>% 
  mutate(gender="femmina")

p0 <- rbind(male, female) %>% 
  ggplot(aes(x=height, y=mass)) + 
  geom_point(aes(color=gender, shape=gender)) + 
  # scale_color_discrete(palette=c("pink", "lightblue")) +
  labs(x="Statura (cm)", y="Peso (kg)", color="Sesso", shape="Sesso") + 
  lims(x=c(140,190), y=c(38, 90))
```

:::columns
:::column
```{r}
p0
```
:::

:::column
```{dot, ref.label="nnet"}
```
:::callout-note
## Addestramento
**Addestrare** la rete significa trovare la combinazione di **pesi** $w_i$ che minimizza il numero di predizioni errate
:::
:::
:::


## Esempio: inferenza

:::columns
:::column
```{r}
rbind(male, female) %>% 
  ggplot(aes(x=height, y=mass)) + 
  geom_point(aes(shape=gender), color=grey(4/5)) + 
  geom_point(
    data=tibble(height=178, mass=82, gender="maschio"),
    aes(color=gender, shape=gender),
    size=3,
    show.legend = F
  ) +
  labs(x="Statura (cm)", y="Peso (kg)", color="Sesso", shape="Sesso") + 
  lims(x=c(140,190), y=c(38, 90))
```
:::

:::column
```{dot nnet2}
digraph nn {
  rankdir="LR";
  splines=false;
  node [fontname="Helvetica", fontsize=12];
  edge [fontname="Helvetica", fontsize=8, fontcolor="#000099"];
  subgraph input {
    label=input;
    altezza [label="178 cm"]
    peso [label="82 kg"]
  }
  subgraph hidden {
    label=hidden;
    n1;
    n2;
    n3;
  }
  subgraph output {
    label=output
    maschio;
    femmina [fontcolor="#888888"];
  }
  
  altezza -> n1 [xlabel="w1"]
  altezza -> n2 [xlabel = "w2"]
  altezza -> n3 [xlabel = "w3"]
  peso -> n1 [xlabel = "w4"]
  peso -> n2 [xlabel = "w5"]
  peso -> n3 [xlabel = "w6"]
  n1 -> maschio [xlabel = "w7"]
  n2 -> maschio [xlabel = "w8"]
  n3 -> maschio [xlabel = "w9"]
  n1 -> femmina [xlabel = "w10"]
  n2 -> femmina [xlabel = "w11"]
  n3 -> femmina [xlabel = "w12"]
}
```
:::callout-important
Ma la risposta è **probabilistica**!!!
:::
:::
:::


## Esempio: inferenza

:::columns
:::column
```{r}
asia <- rbind(male, female) %>% 
  mutate(height=height-8, mass=mass - 12) %>% 
  slice_sample(n=200)

rbind(male, female) %>% 
  ggplot(aes(x=height, y=mass)) + 
  geom_point(aes(shape=gender), color=grey(4/5)) + 
  geom_point(
    data=asia,
    aes(color=gender, shape=gender)
  ) +
  labs(x="Statura (cm)", y="Peso (kg)", color="Sesso", shape="Sesso") + 
  lims(x=c(140,190), y=c(38, 90))
```

:::

:::column
```{dot, ref.label="nnet"}
```
:::callout-warning
## Inferenza su una popolazione differente (es. asiatica)
Se usata su dati troppo diversi dal set di addestramento, fornisce inferenze sbagliate!
:::
:::
:::


## Cosa significa *profonda*

:::{style="text-align: center;"}
![](https://lamarr-institute.org/wp-content/uploads/deepLearn_2_EN.png){width="75%"}
:::

:::callout-important
Valgono le stesse attenzioni che per la regressione lineare, in particolare: necessità di validazione, risposta probabilistica
:::


# {background-iframe="https://nn-vis.noelith.dev"}


## Come siamo arrivati ad oggi

È basata su **quattro pilastri**:

1. la disponibilità di potenza di calcolo per l'addestramento (**GPU, TPU**)
2. la disponibilità di un esteso campione di dati **annotati**
3. la disponibilità di metodi (e strumenti software) computazionali di ottimizzazione (**CUDA, OpenCL**)
4. la disponibilità di strumenti software per semplificare e automatizzare la definizione ad alto livello delle topologie di rete (**TensorFlow, Keras, PyTorch**, etc.)

:::callout-note
Tuttora, i punti 1. e 2. sono quelli più rigidamente collegati ad un costo computazionale ed economico: il primo richiede potenza di calcolo ed **energia**, il secondo richiede **tempo/informazioni**
:::


## Le allucinazioni e l'AI generativa

:::columns
:::column
* Prima applicazione di largo uso: classificazione di immagini
* E se **invertiamo** la DNN? possiamo partire da una classe (es. "cane") e ottenere un'immagine
* È il meccanismo (anche biologico) dell'**allucinazione**
:::

:::column
![Inferenza su un'immagine fotografica](images/hal.dot.png)
:::
:::


## Le allucinazioni e l'AI generativa

:::columns
:::column
* Le prime allucinazioni erano tali anche nell'aspetto
* Ma l'idea, raffinata, ha portato alla **AI generativa**

:::callout-note
Ciò illustra quanto sia errata l'accusa di plagiarismo per le AI generative: l'allucinazione **non è** un *collage* di immagini da un database, ma è una immagine originale generata a partire da un progetto di astrazione--concretizzazione
:::
:::

:::column
![Allucinazione (Ian J. Goodfellow, 2014)](images/goodfellow.png)
:::
:::




## Il passaggio a tecnologia d'uso

* Il vero passaggio della AI a tecnologia d'uso corrente è avvenuto grazie ai **Large Language Model**
* Analogamente alle AI generative, che sono **mappe invertibili** tra il dominio delle classi descrittive e il dominio delle immagini, gli LLM sono **mappe invertibili** tra domini di conoscenza (o *linguaggi*) generici
  - possono tradurre tra lingue
  - possono convertire in formati espressivi diversi
  - possono passare da un dominio espressivo (testo) ad un'altro (linguaggio di programmazione)
  - possono generare immagini a partire da testi (*prompt*)
  
:::callout-warning
Ma lo fanno sempre secondo un **processo probabilistico!**
:::

# I rischi dell'AI

#

:::r-fit-text
Ogni forma sufficientemente avanzata di 

**tecnologia** è indistinguibile dalla **magia**

:::{style="text-align: right;"}
*--- Arthur C. Clarke*
:::
:::




## Rischi generici

* Uso **fideistico/magico**
* Uso a *black-box*: anche comprendendone i principi, la complessità rende il sistema opaco e richiede un **investimento in fiducia**
* Riduzione delle competenze base (*sindrome del "motore a scoppio"*) che comporta un ***lock-in* tecnologico**
* Impatto sociale sul mondo del lavoro
* Impatto sociale psicologico
* Strumento probabilistico ma senza una **stima di confidenza** (e il mercato la scoraggia!)
* *Black-box* anche per gli sviluppatori (è **controllabile**?)
* *Black-box* legale (di chi è la **responsabilità**?)

## Rischi specifici
:::{style="text-align: center;"}
![Ricostruzione di ambienti dal segnale WiFi](https://cdn.mos.cms.futurecdn.net/qwi2P3pXtdDg4MNbqD4ZsN.jpg){width="80%"}
:::

## Rischi specifici
:::{style="text-align: center;"}
![Lettura del pensiero (via MRI)](https://www.science.org/do/10.1126/science.adh4932/abs/_20230307_on_artificial_intelligence_photographs.jpg){width="80%"}
:::

# Grazie dell'attenzione

:::columns
:::column
### Contatto:

[paolo.bosetti@unitn.it](mailto:paolo.bosetti@unitn.it)

{{< qrcode mailto:paolo.bosetti@unitn.it >}}
:::

:::{.column style="text-align: right;"}
### Questo sito:

<https://paolobosetti.quarto.pub/ai-pat>

{{< qrcode https://paolobosetti.quarto.pub/ai-pat >}}
:::
:::

